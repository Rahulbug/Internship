{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546fc524",
   "metadata": {},
   "source": [
    "#1) Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c27a7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ac29318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page1=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b2a57ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1=BeautifulSoup(page1.content)\n",
    "#soup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "02f87c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1  ->  Main Page\n",
      "h1  ->  Welcome to Wikipedia\n",
      "h2  ->  From today's featured article\n",
      "h2  ->  Did you know ...\n",
      "h2  ->  In the news\n",
      "h2  ->  On this day\n",
      "h2  ->  Today's featured picture\n",
      "h2  ->  Other areas of Wikipedia\n",
      "h2  ->  Wikipedia's sister projects\n",
      "h2  ->  Wikipedia languages\n",
      "h2  ->  Navigation menu\n",
      "h3  ->  Personal tools\n",
      "h3  ->  Namespaces\n",
      "h3  ->  Views\n",
      "h3  ->  Search\n",
      "h3  ->  Navigation\n",
      "h3  ->  Contribute\n",
      "h3  ->  Tools\n",
      "h3  ->  Print/export\n",
      "h3  ->  In other projects\n",
      "h3  ->  Languages\n"
     ]
    }
   ],
   "source": [
    "heading_tags = [\"h1\", \"h2\", \"h3\"]\n",
    "for tags in soup1.find_all(heading_tags):\n",
    "    print(tags.name,' -> ', tags.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88effa20",
   "metadata": {},
   "source": [
    "#2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22586ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cbbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7019f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "58d511f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8cc3bb76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moviesname = soup.find_all('h3',class_='lister-item-header')\n",
    "#moviesname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16c8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/title/tt0111161/\">The Shawshank Redemption</a>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesname.a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12febd60",
   "metadata": {},
   "source": [
    "#scraping year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2f9121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = soup.find('span',class_='lister-item-year text-muted unbold')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19c1e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1994)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87bfc4",
   "metadata": {},
   "source": [
    "#scraping rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ceee1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=soup.find('div',class_='inline-block ratings-imdb-rating')['data-value']\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f456f23",
   "metadata": {},
   "source": [
    "#scraping all movie name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1323912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for movies in soup.find_all('h3',class_='lister-item-header'):\n",
    "    \n",
    "    titles.append(movies.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "#titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbf5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping all year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6b9ef4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for a in soup.find_all('span',class_='lister-item-year text-muted unbold'):\n",
    "    years.append(a.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b01a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b150d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for a in soup.find_all('div',class_='inline-block ratings-imdb-rating'):\n",
    "    rating.append(a.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#rating    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b951587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9cddac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>years</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption(1994)</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather(1972)</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Dark Knight(2008)</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Lord of the Rings: The Return of the Kin...</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Schindler's List(1993)</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.North by Northwest(1959)</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Vertigo(1958)</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Singin' in the Rain(1952)</td>\n",
       "      <td>(1952)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Citizen Kane(1941)</td>\n",
       "      <td>(1941)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.M - Eine Stadt sucht einen Mörder(1931)</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titles   years rating\n",
       "0                    1.The Shawshank Redemption(1994)  (1994)    9.3\n",
       "1                               2.The Godfather(1972)  (1972)    9.2\n",
       "2                             3.The Dark Knight(2008)  (2008)    9.0\n",
       "3   4.The Lord of the Rings: The Return of the Kin...  (2003)    9.0\n",
       "4                            5.Schindler's List(1993)  (1993)    9.0\n",
       "..                                                ...     ...    ...\n",
       "95                        96.North by Northwest(1959)  (1959)    8.3\n",
       "96                                   97.Vertigo(1958)  (1958)    8.3\n",
       "97                       98.Singin' in the Rain(1952)  (1952)    8.3\n",
       "98                              99.Citizen Kane(1941)  (1941)    8.3\n",
       "99        100.M - Eine Stadt sucht einen Mörder(1931)  (1931)    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'titles':titles,'years':years,'rating':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394784d5",
   "metadata": {},
   "source": [
    "#3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cf6cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3499ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls063915608/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7963bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39a06df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping movie name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ece9cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"lister-item-header\">\n",
       "<span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       "<a href=\"/title/tt0405508/\">Rang De Basanti</a>\n",
       "<span class=\"lister-item-year text-muted unbold\">(2006)</span>\n",
       "</h3>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = soup.find('h3',class_='lister-item-header')\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a280cd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rang De Basanti'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name.a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4a747c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06ed608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"lister-item-year text-muted unbold\">(2006)</span>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_year = soup.find('span',class_='lister-item-year text-muted unbold')\n",
    "re_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5773f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2006)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_year.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57e7bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "18c54665",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_rating = soup.find('div',class_='ipl-rating-star small')\n",
    "#re_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebff2b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n8.1\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_rating.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "471166ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping all movie name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "750a2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = []\n",
    "\n",
    "for movies in soup.find_all('h3',class_='lister-item-header'):\n",
    "    \n",
    "    movie_name.append(movies.text.replace('\\n',''))\n",
    "    \n",
    "#movie_name    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e51c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping all year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e34a5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_year = []\n",
    "\n",
    "for a in soup.find_all('span',class_='lister-item-year text-muted unbold'):\n",
    "    re_year.append(a.text.replace('\\n',''))\n",
    "    \n",
    "#re_year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dad06a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarping all rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3a8fd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_rating = []\n",
    "\n",
    "for a in soup.find_all('div',class_='ipl-rating-star small'):\n",
    "    re_rating.append(a.text.replace('\\n',''))\n",
    "    \n",
    "#re_rating    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "099a7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88f6a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>re_year</th>\n",
       "      <th>re_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Rang De Basanti(2006)</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Lagaan: Once Upon a Time in India(2001)</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.Dil Chahta Hai(2001)</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.Gangs of Wasseypur(2012)</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Zindagi Na Milegi Dobara(2011)</td>\n",
       "      <td>(2011)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Dhamaal(2007)</td>\n",
       "      <td>(2007)</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Golmaal: Fun Unlimited(2006)</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Aligarh(2015)</td>\n",
       "      <td>(2015)</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Earth(1998)</td>\n",
       "      <td>(1998)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Kapoor &amp; Sons(2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   movie_name re_year re_rating\n",
       "0                     1.Rang De Basanti(2006)  (2006)       8.1\n",
       "1   2.Lagaan: Once Upon a Time in India(2001)  (2001)       8.1\n",
       "2                      3.Dil Chahta Hai(2001)  (2001)       8.1\n",
       "3                  4.Gangs of Wasseypur(2012)  (2012)       8.2\n",
       "4            5.Zindagi Na Milegi Dobara(2011)  (2011)       8.2\n",
       "..                                        ...     ...       ...\n",
       "95                           96.Dhamaal(2007)  (2007)       7.4\n",
       "96            97.Golmaal: Fun Unlimited(2006)  (2006)       7.4\n",
       "97                           98.Aligarh(2015)  (2015)       7.8\n",
       "98                             99.Earth(1998)  (1998)       7.6\n",
       "99                    100.Kapoor & Sons(2016)  (2016)       7.7\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'movie_name':movie_name,'re_year':re_year,'re_rating':re_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de158b",
   "metadata": {},
   "source": [
    "4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8c5719af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from bs4 import BeautifulSoup,NavigableString\n",
    "import requests\n",
    "page3=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "soup3=BeautifulSoup(page3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "77899a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Former_president=soup3.find_all(\"h3\")\n",
    "President_name=[]\n",
    "for i in Former_president:\n",
    "    President_name.append((i.text)[:-14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "868c7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "term=soup3.find_all(\"div\",{\"class\":\"presidentListing\"})\n",
    "Term_of_Office=[]\n",
    "for i in term:\n",
    "    n=0\n",
    "    m=0\n",
    "    for j in list(i.text):\n",
    "        m+=1\n",
    "        if j==\"\\n\":\n",
    "            n+=1\n",
    "        if n==2:\n",
    "            break\n",
    "    list1=list(i.text)[m+15:]\n",
    "    a=0\n",
    "    b=0\n",
    "    for k in list1:\n",
    "        b+=1\n",
    "        if k=='\\n':\n",
    "            a+=1\n",
    "        if a==1:\n",
    "            break\n",
    "    list2=list1[:b-1]\n",
    "    def listToString(s):\n",
    "        # initialize an empty string\n",
    "        str1 = \"\"\n",
    "        # return string \n",
    "        return (str1.join(s))\n",
    "    Term_of_Office.append(listToString(list2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "579b2c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************Former Presidents******************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President_Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term_Of_Office</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25 July, 2017 to 25 July, 2022</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 2012 to 25 July, 2017</th>\n",
       "      <td>Shri Pranab Mukherj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 2007 to 25 July, 2012</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 2002 to 25 July, 2007</th>\n",
       "      <td>DR. A.P.J. Abdul Kal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 1997 to 25 July, 2002</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 1992 to 25 July, 1997</th>\n",
       "      <td>Dr Shankar Dayal Shar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 1987 to 25 July, 1992</th>\n",
       "      <td>Shri R Venkataram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 1982 to 25 July, 1987</th>\n",
       "      <td>Giani Zail Sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 July, 1977 to 25 July, 1982</th>\n",
       "      <td>Shri Neelam Sanjiva Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24 August, 1974 to 11 February, 1977</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974</th>\n",
       "      <td>Shri Varahagiri Venkata Gi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 May, 1967 to 3 May, 1969</th>\n",
       "      <td>Dr. Zakir Husa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 May, 1962 to 13 May, 1967</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26 January, 1950 to 13 May, 1962</th>\n",
       "      <td>Dr. Rajendra Prasa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   President_Name\n",
       "Term_Of_Office                                                                   \n",
       " 25 July, 2017 to 25 July, 2022                             Shri Ram Nath Kovind \n",
       " 25 July, 2012 to 25 July, 2017                               Shri Pranab Mukherj\n",
       " 25 July, 2007 to 25 July, 2012                     Smt Pratibha Devisingh Patil \n",
       " 25 July, 2002 to 25 July, 2007                              DR. A.P.J. Abdul Kal\n",
       " 25 July, 1997 to 25 July, 2002                              Shri K. R. Narayanan\n",
       " 25 July, 1992 to 25 July, 1997                             Dr Shankar Dayal Shar\n",
       " 25 July, 1987 to 25 July, 1992                                 Shri R Venkataram\n",
       " 25 July, 1982 to 25 July, 1987                                    Giani Zail Sin\n",
       " 25 July, 1977 to 25 July, 1982                           Shri Neelam Sanjiva Red\n",
       " 24 August, 1974 to 11 February, 1977                      Dr. Fakhruddin Ali Ahm\n",
       " 3 May, 1969 to 20 July, 1969 and 24 August, 19...     Shri Varahagiri Venkata Gi\n",
       " 13 May, 1967 to 3 May, 1969                                       Dr. Zakir Husa\n",
       " 13 May, 1962 to 13 May, 1967                          Dr. Sarvepalli Radhakrishn\n",
       " 26 January, 1950 to 13 May, 1962                              Dr. Rajendra Prasa"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Former_Presidents_of_India=pd.DataFrame(list(zip(President_name,Term_of_Office)),columns=[\"President_Name\",\"Term_Of_Office\"])\n",
    "print(\"******************************************Former Presidents******************************************\")\n",
    "Former_Presidents_of_India.set_index(\"Term_Of_Office\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37f0d0",
   "metadata": {},
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "#c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82deaa9",
   "metadata": {},
   "source": [
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9373758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4b93d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODITeamNames=soup.find_all(\"span\",{\"class\":\"u-hide-phablet\"})\n",
    "ODI_Team_names=[]\n",
    "for i in ODITeamNames:\n",
    "    ODI_Team_names.append((i.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e1df5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODITeamMatches=soup.find_all(\"tr\",{\"class\":\"table-body\"})\n",
    "ODI_Teams_matches=[]\n",
    "for i in ODITeamMatches:\n",
    "    n=0\n",
    "    m=0\n",
    "    for j in list(i.text):\n",
    "        m+=1\n",
    "        if j==\"\\n\":\n",
    "            n+=1\n",
    "        if n==7:\n",
    "            break\n",
    "    list1=list(i.text)[m:]\n",
    "    a=0\n",
    "    b=0\n",
    "    for k in list1:\n",
    "        b+=1\n",
    "        if k=='\\n':\n",
    "            a+=1\n",
    "        if a==1:\n",
    "            break\n",
    "    list2=list1[:b-1]\n",
    "    def listToString(s):\n",
    "        # initialize an empty string\n",
    "        str1 = \"\"\n",
    "        # return string \n",
    "        return (str1.join(s))\n",
    "    ODI_Teams_matches.append(listToString(list2)) \n",
    "ODI_Teams_matches.insert(0,\"19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9cd9bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODITeamPoints=soup.find_all(\"tr\",{\"class\":\"table-body\"})\n",
    "ODI_Team_points=[]\n",
    "for i in ODITeamPoints:\n",
    "    n=0\n",
    "    m=0\n",
    "    for j in list(i.text):\n",
    "        m+=1\n",
    "        if j==\"\\n\":\n",
    "            n+=1\n",
    "        if n==8:\n",
    "            break\n",
    "    list1=list(i.text)[m:]\n",
    "    a=0\n",
    "    b=0\n",
    "    for k in list1:\n",
    "        b+=1\n",
    "        if k=='\\n':\n",
    "            a+=1\n",
    "        if a==1:\n",
    "            break\n",
    "    list2=list1[:b-1]\n",
    "    def listToString(s):\n",
    "        # initialize an empty string\n",
    "        str1 = \"\"\n",
    "        # return string \n",
    "        return (str1.join(s))\n",
    "    ODI_Team_points.append(listToString(list2))  \n",
    "ODI_Team_points.insert(0,\"2,355\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "867e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODITeamRatings=soup.find_all(\"tr\",{\"class\":\"table-body\"})\n",
    "ODI_Teams_ratings=[]\n",
    "for i in ODITeamPoints:\n",
    "    n=0\n",
    "    m=0\n",
    "    for j in list(i.text):\n",
    "        m+=1\n",
    "        if j==\"\\n\":\n",
    "            n+=1\n",
    "        if n==9:\n",
    "            break\n",
    "    list1=list(i.text)[m:]\n",
    "    a=0\n",
    "    b=0\n",
    "    for k in list1:\n",
    "        b+=1\n",
    "        if k=='\\n':\n",
    "            a+=1\n",
    "        if a==1:\n",
    "            break\n",
    "    list2=list1[:b-1]\n",
    "    def listToString(s):\n",
    "        # initialize an empty string\n",
    "        str1 = \"\"\n",
    "        # return string \n",
    "        return (str1.join(s))\n",
    "    ODI_Teams_ratings.append(listToString(list2))  \n",
    "ODI_Teams_ratings.insert(0,\"124\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9ecc9a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********Men's ODI TOP 10 Team Rankings*********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countries</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>19</td>\n",
       "      <td>2,355</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sri Lanka</th>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Indies</th>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Matches Points Rating\n",
       "Countries                         \n",
       "England           19  2,355    124\n",
       "New Zealand       22  2,508    114\n",
       "India             31  3,447    111\n",
       "Pakistan          22  2,354    107\n",
       "Australia         29  3,071    106\n",
       "South Africa      21  2,111    101\n",
       "Bangladesh        30  2,753     92\n",
       "Sri Lanka         29  2,658     92\n",
       "West Indies       41  2,902     71\n",
       "Afghanistan       18  1,238     69"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI=pd.DataFrame(list(zip(ODI_Team_names,ODI_Teams_matches,ODI_Team_points,ODI_Teams_ratings)),columns=[\"Countries\",\"Matches\",\"Points\",\"Rating\"])\n",
    "print(\"*********Men's ODI TOP 10 Team Rankings*********\")\n",
    "ODI=ODI.set_index(\"Countries\").head(10)\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff214f4e",
   "metadata": {},
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d6120bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fb53afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********ODI TOP 10 Player's Ranking*********\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Babar Azam</th>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rassie van der Dussen</th>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quinton de Kock</th>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imam-ul-Haq</th>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virat Kohli</th>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rohit Sharma</th>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonny Bairstow</th>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Warner</th>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ross Taylor</th>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve Smith</th>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Team Ranking\n",
       "Player                            \n",
       "Babar Azam             PAK     890\n",
       "Rassie van der Dussen   SA     789\n",
       "Quinton de Kock         SA     784\n",
       "Imam-ul-Haq            PAK     779\n",
       "Virat Kohli            IND     744\n",
       "Rohit Sharma           IND     740\n",
       "Jonny Bairstow         ENG     732\n",
       "David Warner           AUS     725\n",
       "Ross Taylor             NZ     701\n",
       "Steve Smith            AUS     697"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_Batsmen=soup.find_all(\"td\",{\"class\":\"name\"})\n",
    "batMens=[\"Babar Azam\"]\n",
    "for i in Top_10_Batsmen:\n",
    "    batMens.append((i.text).replace(\"\\n\",\"\"))\n",
    "Team=[\"PAK\"]\n",
    "for i in soup.find_all(\"span\",{\"class\":\"table-body__logo-text\"}):\n",
    "    Team.append(i.text)\n",
    "Ranking=[\"890\"]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"rating\"}):\n",
    "    Ranking.append(i.text)\n",
    "ODI=pd.DataFrame(list(zip(batMens,Team,Ranking)),columns=[\"Player\",\"Team\",\"Ranking\"]).head(10).set_index(\"Player\")\n",
    "print(\"*********ODI TOP 10 Player's Ranking*********\")\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c14b1a",
   "metadata": {},
   "source": [
    "#c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a6ca8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1203247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ODI TOP 10 Bowler's Ranking**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trent Boult</th>\n",
       "      <td>NZ</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Josh Hazlewood</th>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mujeeb Ur Rahman</th>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jasprit Bumrah</th>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shaheen Afridi</th>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mohammad Nabi</th>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mehedi Hasan</th>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matt Henry</th>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchell Starc</th>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rashid Khan</th>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team Rating\n",
       "Player                      \n",
       "Trent Boult        NZ    720\n",
       "Josh Hazlewood    AUS    718\n",
       "Mujeeb Ur Rahman  AFG    676\n",
       "Jasprit Bumrah    IND    662\n",
       "Shaheen Afridi    PAK    661\n",
       "Mohammad Nabi     AFG    657\n",
       "Mehedi Hasan      BAN    655\n",
       "Matt Henry         NZ    654\n",
       "Mitchell Starc    AUS    653\n",
       "Rashid Khan       AFG    651"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player=[\"Trent Boult\"]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"name\"}):\n",
    "    Player.append((i.text).replace(\"\\n\",\"\"))\n",
    "Team=[\"NZ\"]\n",
    "for i in soup.find_all(\"span\",{\"class\":\"table-body__logo-text\"}):\n",
    "    Team.append(i.text)\n",
    "Rating=[\"720\"]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"rating\"}):\n",
    "    Rating.append(i.text)\n",
    "ODI=pd.DataFrame(list(zip(Player,Team,Rating)),columns=[\"Player\",\"Team\",\"Rating\"]).head(10).set_index(\"Player\")\n",
    "print(\"**ODI TOP 10 Bowler's Ranking**\")\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab0300",
   "metadata": {},
   "source": [
    "#6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e139a",
   "metadata": {},
   "source": [
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "56da1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "93ef2414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Top 10 Women's ODI Team Rankings***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>36</td>\n",
       "      <td>4,205</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>35</td>\n",
       "      <td>3,732</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>33</td>\n",
       "      <td>3,302</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Indies</th>\n",
       "      <td>32</td>\n",
       "      <td>2,864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ireland</th>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sri Lanka</th>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Matches Points Rating\n",
       "Team                              \n",
       "Australia         29  4,837    167\n",
       "South Africa      35  4,157    119\n",
       "England           36  4,205    117\n",
       "India             35  3,732    107\n",
       "New Zealand       33  3,302    100\n",
       "West Indies       32  2,864     90\n",
       "Bangladesh        12    930     78\n",
       "Pakistan          30  1,962     65\n",
       "Ireland           11    516     47\n",
       "Sri Lanka         11    495     45\n",
       "Zimbabwe           8      0      0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Team=[]\n",
    "Matches=[\"29\"]\n",
    "Points=[\"4,837\"]\n",
    "Rating=[\"167\"]\n",
    "for i in soup.find_all(\"span\",{\"class\":\"u-hide-phablet\"}):\n",
    "    Team.append(i.text)\n",
    "for i in soup.find_all(\"td\",{\"class\":\"rating\"}):\n",
    "    Rating.append(i.text)\n",
    "n=0\n",
    "for i in soup.find_all(\"td\",{\"class\":\"table-body__cell u-center-text\"}):\n",
    "    n+=1\n",
    "    if n%2==0:\n",
    "        Points.append(i.text)\n",
    "    else:\n",
    "        Matches.append(i.text)\n",
    "ODI=(pd.DataFrame(list(zip(Team,Matches,Points,Rating)),columns=[\"Team\",\"Matches\",\"Points\",\"Rating\"])).set_index(\"Team\")\n",
    "print(\"***Top 10 Women's ODI Team Rankings***\")\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bac42",
   "metadata": {},
   "source": [
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fcdd1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9d88edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Top 10 Women's ODI Batting players***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alyssa Healy</th>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beth Mooney</th>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natalie Sciver</th>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laura Wolvaardt</th>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meg Lanning</th>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rachael Haynes</th>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smriti Mandhana</th>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy Satterthwaite</th>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmanpreet Kaur</th>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chamari Athapaththu</th>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Team Rating\n",
       "Player                         \n",
       "Alyssa Healy         AUS    785\n",
       "Beth Mooney          AUS    749\n",
       "Natalie Sciver       ENG    740\n",
       "Laura Wolvaardt       SA    732\n",
       "Meg Lanning          AUS    710\n",
       "Rachael Haynes       AUS    701\n",
       "Smriti Mandhana      IND    698\n",
       "Amy Satterthwaite     NZ    681\n",
       "Harmanpreet Kaur     IND    662\n",
       "Chamari Athapaththu   SL    655"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player=[\"Alyssa Healy\"]\n",
    "Team=['AUS']\n",
    "Rating=[\"785\"]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"name\"}):\n",
    "    Player.append((i.text).replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",{\"class\":\"table-body__logo-text\"}):\n",
    "    Team.append((i.text).replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",{\"class\":\"rating\"}):\n",
    "    Rating.append((i.text).replace(\"\\n\",\"\"))\n",
    "ODI=(pd.DataFrame(list(zip(Player,Team,Rating)),columns=[\"Player\",\"Team\",\"Rating\"]).head(10)).set_index(\"Player\")\n",
    "print(\"***Top 10 Women's ODI Batting players***\")\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75927e76",
   "metadata": {},
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f69a9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0aff4dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Top 10 women’s ODI all-rounder players***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Natalie Sciver</th>\n",
       "      <td>ENG</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natalie Sciver</th>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marizanne Kapp</th>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hayley Matthews</th>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amelia Kerr</th>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deepti Sharma</th>\n",
       "      <td>IND</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ashleigh Gardner</th>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jess Jonassen</th>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jhulan Goswami</th>\n",
       "      <td>IND</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophie Ecclestone</th>\n",
       "      <td>ENG</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Team Rating\n",
       "Player                       \n",
       "Natalie Sciver     ENG    379\n",
       "Natalie Sciver     ENG    372\n",
       "Marizanne Kapp      SA    349\n",
       "Hayley Matthews     WI    339\n",
       "Amelia Kerr         NZ    336\n",
       "Deepti Sharma      IND    271\n",
       "Ashleigh Gardner   AUS    270\n",
       "Jess Jonassen      AUS    246\n",
       "Jhulan Goswami     IND    219\n",
       "Sophie Ecclestone  ENG    217"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player=[\"Natalie Sciver\"]\n",
    "Team=['ENG']\n",
    "Rating=[\"379\"]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"name\"}):\n",
    "    Player.append((i.text).replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",{\"class\":\"table-body__logo-text\"}):\n",
    "    Team.append((i.text).replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",{\"class\":\"rating\"}):\n",
    "    Rating.append((i.text).replace(\"\\n\",\"\"))\n",
    "ODI=(pd.DataFrame(list(zip(Player,Team,Rating)),columns=[\"Player\",\"Team\",\"Rating\"]).head(10)).set_index(\"Player\")\n",
    "print(\"***Top 10 women’s ODI all-rounder players***\")\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac6e66",
   "metadata": {},
   "source": [
    "#7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "#iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b103d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e787d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News Headings</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North Korea fires ballistic missile into sea ahead of visit by U.S. VP Kamala Harris</th>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/25/north-korea-fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ether is down almost 20% since the merge. Here’s what’s going on</th>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/ether-is-down-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      News Time  \\\n",
       "News Headings                                                     \n",
       "North Korea fires ballistic missile into sea ah...  2 hours ago   \n",
       "Ether is down almost 20% since the merge. Here’...  2 hours ago   \n",
       "\n",
       "                                                                                            News Link  \n",
       "News Headings                                                                                          \n",
       "North Korea fires ballistic missile into sea ah...  https://www.cnbc.com/2022/09/25/north-korea-fi...  \n",
       "Ether is down almost 20% since the merge. Here’...  https://www.cnbc.com/2022/09/23/ether-is-down-...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Heading_content=soup.find_all(\"div\",{\"class\":\"RiverHeadline-headline RiverHeadline-hasThumbnail\"})\n",
    "Heading=[]\n",
    "Time=[]\n",
    "Link=[]\n",
    "for i in Heading_content:\n",
    "    Heading.append(i.text)\n",
    "for i in soup.find_all(\"span\",{\"class\":\"RiverByline-datePublished\"}):\n",
    "    Time.append(i.text)\n",
    "for i in soup.find_all('div',{\"class\":\"RiverHeadline-headline RiverHeadline-hasThumbnail\"}):\n",
    "    a = (i.findAll('a'))\n",
    "    for a in a:\n",
    "        if str(a.attrs['href'])==\"/pro/\":\n",
    "            pass\n",
    "        else:\n",
    "            Link.append(a.attrs['href'])\n",
    "News=(pd.DataFrame(list(zip(Heading,Time,Link)),columns=[\"News Headings\",\"News Time\",\"News Link\"])).set_index(\"News Headings\")\n",
    "News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5da57",
   "metadata": {},
   "source": [
    "#8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "#https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "#Scrape below mentioned details :\n",
    "#i) Paper Title \n",
    "#ii) Authors\n",
    "#iii) Published Date \n",
    "#iv) Paper URL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e1d1c2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Date</th>\n",
       "      <th>Paper_URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper_Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reward is enough</th>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Making sense of raw input</th>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Law and logic: A review from an argumentation perspective</th>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creativity and artificial intelligence</th>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artificial cognition for social human–robot interaction: An implementation</th>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explanation in artificial intelligence: Insights from the social sciences</th>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Making sense of sensory input</th>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conflict-based search for optimal multi-agent pathfinding</th>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning</th>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hanabi challenge: A new frontier for AI research</th>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluating XAI: A comparison of rule-based and example-based explanations</th>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argumentation in artificial intelligence</th>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms for computing strategies in two-player simultaneous move games</th>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple object tracking: A literature review</th>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selection of relevant features and examples in machine learning</th>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A survey of inverse reinforcement learning: Challenges, methods and progress</th>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explaining individual predictions when features are dependent: More accurate approximations to Shapley values</th>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A review of possible effects of cognitive biases on interpretation of rule-based machine learning models</th>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Integrating social power into the decision-making of cognitive agents</th>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems</th>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies</th>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm runtime prediction: Methods &amp; evaluation</th>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrappers for feature subset selection</th>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics</th>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantum computation, quantum theory and AI</th>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              Authors  \\\n",
       "Paper_Title                                                                                             \n",
       "Reward is enough                                    Silver, David, Singh, Satinder, Precup, Doina,...   \n",
       "Making sense of raw input                                   Evans, Richard, Bošnjak, Matko and 5 more   \n",
       "Law and logic: A review from an argumentation p...                  Prakken, Henry, Sartor, Giovanni    \n",
       "Creativity and artificial intelligence                                            Boden, Margaret A.    \n",
       "Artificial cognition for social human–robot int...    Lemaignan, Séverin, Warnier, Mathieu and 3 more   \n",
       "Explanation in artificial intelligence: Insight...                                       Miller, Tim    \n",
       "Making sense of sensory input                       Evans, Richard, Hernández-Orallo, José and 3 more   \n",
       "Conflict-based search for optimal multi-agent p...  Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   \n",
       "Between MDPs and semi-MDPs: A framework for tem...  Sutton, Richard S., Precup, Doina, Singh, Sati...   \n",
       "The Hanabi challenge: A new frontier for AI res...        Bard, Nolan, Foerster, Jakob N. and 13 more   \n",
       "Evaluating XAI: A comparison of rule-based and ...  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   \n",
       "Argumentation in artificial intelligence                         Bench-Capon, T.J.M., Dunne, Paul E.    \n",
       "Algorithms for computing strategies in two-play...       Bošanský, Branislav, Lisý, Viliam and 3 more   \n",
       "Multiple object tracking: A literature review                  Luo, Wenhan, Xing, Junliang and 4 more   \n",
       "Selection of relevant features and examples in ...                      Blum, Avrim L., Langley, Pat    \n",
       "A survey of inverse reinforcement learning: Cha...                   Arora, Saurabh, Doshi, Prashant    \n",
       "Explaining individual predictions when features...      Aas, Kjersti, Jullum, Martin, Løland, Anders    \n",
       "A review of possible effects of cognitive biase...  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...   \n",
       "Integrating social power into the decision-maki...    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    \n",
       "“That's (not) the output I expected!” On the ro...                      Riveiro, Maria, Thill, Serge    \n",
       "Explaining black-box classifiers using post-hoc...  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...   \n",
       "Algorithm runtime prediction: Methods & evaluation  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...   \n",
       "Wrappers for feature subset selection                                   Kohavi, Ron, John, George H.    \n",
       "Commonsense visual sensemaking for autonomous d...  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...   \n",
       "Quantum computation, quantum theory and AI                                           Ying, Mingsheng    \n",
       "\n",
       "                                                    Published_Date  \\\n",
       "Paper_Title                                                          \n",
       "Reward is enough                                      October 2021   \n",
       "Making sense of raw input                             October 2021   \n",
       "Law and logic: A review from an argumentation p...    October 2015   \n",
       "Creativity and artificial intelligence                 August 1998   \n",
       "Artificial cognition for social human–robot int...       June 2017   \n",
       "Explanation in artificial intelligence: Insight...   February 2019   \n",
       "Making sense of sensory input                           April 2021   \n",
       "Conflict-based search for optimal multi-agent p...   February 2015   \n",
       "Between MDPs and semi-MDPs: A framework for tem...     August 1999   \n",
       "The Hanabi challenge: A new frontier for AI res...      March 2020   \n",
       "Evaluating XAI: A comparison of rule-based and ...   February 2021   \n",
       "Argumentation in artificial intelligence              October 2007   \n",
       "Algorithms for computing strategies in two-play...     August 2016   \n",
       "Multiple object tracking: A literature review           April 2021   \n",
       "Selection of relevant features and examples in ...   December 1997   \n",
       "A survey of inverse reinforcement learning: Cha...     August 2021   \n",
       "Explaining individual predictions when features...  September 2021   \n",
       "A review of possible effects of cognitive biase...       June 2021   \n",
       "Integrating social power into the decision-maki...   December 2016   \n",
       "“That's (not) the output I expected!” On the ro...  September 2021   \n",
       "Explaining black-box classifiers using post-hoc...        May 2021   \n",
       "Algorithm runtime prediction: Methods & evaluation    January 2014   \n",
       "Wrappers for feature subset selection                December 1997   \n",
       "Commonsense visual sensemaking for autonomous d...    October 2021   \n",
       "Quantum computation, quantum theory and AI           February 2010   \n",
       "\n",
       "                                                                                            Paper_URL  \n",
       "Paper_Title                                                                                            \n",
       "Reward is enough                                    https://www.sciencedirect.com/science/article/...  \n",
       "Making sense of raw input                           https://www.sciencedirect.com/science/article/...  \n",
       "Law and logic: A review from an argumentation p...  https://www.sciencedirect.com/science/article/...  \n",
       "Creativity and artificial intelligence              https://www.sciencedirect.com/science/article/...  \n",
       "Artificial cognition for social human–robot int...  https://www.sciencedirect.com/science/article/...  \n",
       "Explanation in artificial intelligence: Insight...  https://www.sciencedirect.com/science/article/...  \n",
       "Making sense of sensory input                       https://www.sciencedirect.com/science/article/...  \n",
       "Conflict-based search for optimal multi-agent p...  https://www.sciencedirect.com/science/article/...  \n",
       "Between MDPs and semi-MDPs: A framework for tem...  https://www.sciencedirect.com/science/article/...  \n",
       "The Hanabi challenge: A new frontier for AI res...  https://www.sciencedirect.com/science/article/...  \n",
       "Evaluating XAI: A comparison of rule-based and ...  https://www.sciencedirect.com/science/article/...  \n",
       "Argumentation in artificial intelligence            https://www.sciencedirect.com/science/article/...  \n",
       "Algorithms for computing strategies in two-play...  https://www.sciencedirect.com/science/article/...  \n",
       "Multiple object tracking: A literature review       https://www.sciencedirect.com/science/article/...  \n",
       "Selection of relevant features and examples in ...  https://www.sciencedirect.com/science/article/...  \n",
       "A survey of inverse reinforcement learning: Cha...  https://www.sciencedirect.com/science/article/...  \n",
       "Explaining individual predictions when features...  https://www.sciencedirect.com/science/article/...  \n",
       "A review of possible effects of cognitive biase...  https://www.sciencedirect.com/science/article/...  \n",
       "Integrating social power into the decision-maki...  https://www.sciencedirect.com/science/article/...  \n",
       "“That's (not) the output I expected!” On the ro...  https://www.sciencedirect.com/science/article/...  \n",
       "Explaining black-box classifiers using post-hoc...  https://www.sciencedirect.com/science/article/...  \n",
       "Algorithm runtime prediction: Methods & evaluation  https://www.sciencedirect.com/science/article/...  \n",
       "Wrappers for feature subset selection               https://www.sciencedirect.com/science/article/...  \n",
       "Commonsense visual sensemaking for autonomous d...  https://www.sciencedirect.com/science/article/...  \n",
       "Quantum computation, quantum theory and AI          https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "Paper_Title=[]\n",
    "Authors=[]\n",
    "Published_Date=[]\n",
    "Paper_URL=[]\n",
    "for i in soup.find_all(\"h2\",{\"class\":\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"}):\n",
    "    Paper_Title.append(i.text)\n",
    "for i in soup.find_all(\"span\",{\"class\":\"sc-1w3fpd7-0 pgLAT\"}):\n",
    "    Authors.append(i.text)\n",
    "for i in soup.find_all(\"span\",{\"class\":\"sc-1thf9ly-2 bKddwo\"}):\n",
    "    Published_Date.append(i.text)\n",
    "for i in soup.find_all(\"article\"):\n",
    "    a=i.find_all(\"a\")\n",
    "    for x in a:\n",
    "        Paper_URL.append(x.attrs['href'])\n",
    "Result=(pd.DataFrame(list(zip(Paper_Title,Authors,Published_Date,Paper_URL)),columns=[\"Paper_Title\",\"Authors\",\"Published_Date\",\"Paper_URL\"])).set_index(\"Paper_Title\")\n",
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cafa750",
   "metadata": {},
   "source": [
    "#9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "#i) Restaurant name\n",
    "#ii) Cuisine\n",
    "#iii) Location \n",
    "#iv) Ratings\n",
    "#v) Image URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d87feaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image_Url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resturent_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Connaught Clubhouse Microbrewery</th>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38 Barracks</th>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Luggage Room By Sandoz</th>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master Of Malts</th>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Location Rating  \\\n",
       "Resturent_Name                                                            \n",
       "Connaught Clubhouse Microbrewery  Connaught Place, Central Delhi    4.3   \n",
       "38 Barracks                       Connaught Place, Central Delhi    4.3   \n",
       "The Luggage Room By Sandoz        Connaught Place, Central Delhi    3.9   \n",
       "Master Of Malts                   Connaught Place, Central Delhi    4.1   \n",
       "\n",
       "                                                                          Image_Url  \n",
       "Resturent_Name                                                                       \n",
       "Connaught Clubhouse Microbrewery  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "38 Barracks                       https://im1.dineout.co.in/images/uploads/resta...  \n",
       "The Luggage Room By Sandoz        https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Master Of Malts                   https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://www.dineout.co.in/\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "Resturent_Name=[]\n",
    "Cuisine=[]\n",
    "Location=[]\n",
    "Rating=[]\n",
    "Image_URL=[]\n",
    "for i in soup.find_all(\"h4\",{\"class\":\"_1jbOb\"}):\n",
    "    Resturent_Name.append(i.text)\n",
    "for i in soup.find_all(\"p\",{\"class\":\"_1jbOb\"}):\n",
    "    Location.append(i.text)\n",
    "for i in soup.find_all(\"div\",{\"class\":\"kGUdK _1oTbl\"}):\n",
    "    Rating.append(i.text)\n",
    "for i in soup.find_all(\"div\",{\"class\":\"_2DVRC\"}):\n",
    "    a=i.find_all(\"img\")\n",
    "    for x in a:\n",
    "        Image_URL.append(x.attrs['data-src'])\n",
    "Result=(pd.DataFrame(list(zip(Resturent_Name,Location,Rating,Image_URL)),columns=[\"Resturent_Name\",\"Location\",\"Rating\",\"Image_Url\"])).set_index(\"Resturent_Name\")\n",
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79497c4c",
   "metadata": {},
   "source": [
    "#10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "#https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "#i) Rank \n",
    "#ii) Publication\n",
    "#iii) h5-index\n",
    "#iv) h5-media\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "037f84f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5index</th>\n",
       "      <th>h5median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.</th>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.</th>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.</th>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.</th>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.</th>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Publication h5index h5median\n",
       "Rank                                                                    \n",
       "1.                                               Nature     444      667\n",
       "2.                  The New England Journal of Medicine     432      780\n",
       "3.                                              Science     401      614\n",
       "4.    IEEE/CVF Conference on Computer Vision and Pat...     389      627\n",
       "5.                                           The Lancet     354      635\n",
       "...                                                 ...     ...      ...\n",
       "96.                        Journal of Business Research     145      233\n",
       "97.                                    Molecular Cancer     145      209\n",
       "98.                                             Sensors     145      201\n",
       "99.                               Nature Climate Change     144      228\n",
       "100.                    IEEE Internet of Things Journal     144      212\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "Rank=[]\n",
    "Publication=[]\n",
    "h5index=[]\n",
    "h5median=[]\n",
    "for i in soup.find_all(\"td\",{\"class\":\"gsc_mvt_p\"}):\n",
    "    Rank.append(i.text)\n",
    "for i in soup.find_all(\"td\",{\"class\":\"gsc_mvt_t\"}):\n",
    "    Publication.append(i.text)\n",
    "for i in soup.find_all(\"a\",{\"class\":\"gs_ibl gsc_mp_anchor\"}):\n",
    "    h5index.append(i.text)\n",
    "for i in soup.find_all(\"span\",{\"class\":\"gs_ibl gsc_mp_anchor\"}):\n",
    "    h5median.append(i.text)\n",
    "Result=(pd.DataFrame(list(zip(Rank,Publication,h5index,h5median)),columns=[\"Rank\",\"Publication\",\"h5index\",\"h5median\"])).set_index(\"Rank\")\n",
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128ccff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
